{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kPQNxwmEchpa"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten, LSTM, GRU, Conv1D, GlobalMaxPooling1D\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load your JSON file\n",
        "with open('dataset/final2_json_pak_const.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Extract questions and answers\n",
        "questions = [pair['question'] for pair in data]\n",
        "answers = [pair['answer'] for pair in data]\n",
        "# Tokenize the questions\n",
        "tokenizer = Tokenizer()\n",
        "sequences = tokenizer.texts_to_sequences(questions)\n",
        "max_length = max(len(seq) for seq in sequences)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# Calculate vocab_size\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Plus one for the padding token\n",
        "\n",
        "# Encode the answers\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_answers = label_encoder.fit_transform(answers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "37421Cx-fCIj"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Load the tokenizer\n",
        "with open('tokenizer/tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGy7buWrmfXl",
        "outputId": "71b20b9c-b714-4db4-e3c6-37eb0306cffa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the models\n",
        "ann_model = load_model('saved_models/ann_chatbot_model.h5')\n",
        "lstm_model = load_model('saved_models/lstm_chatbot_model.h5')\n",
        "gru_model = load_model('saved_models/gru_chatbot_model.h5')\n",
        "lstm_enhanced_model = load_model('saved_models/lstm_enhanced_chatbot_model.h5')\n",
        "gru_enhanced_model = load_model('saved_models/gru_enhanced_chatbot_model.h5')\n",
        "cnn_enhanced_model = load_model('saved_models/cnn_enhanced_chatbot_model.h5')\n",
        "\n",
        "# Now you can use these models in your prediction loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJXYjmWycKnt",
        "outputId": "653b5a3f-1316-4060-a8bd-8cf6ac55b623"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question 1: Question: When was the Constitution of the Islamic Republic of Pakistan passed and authenticated by the President of the Assembly?\n",
            "Correct Answer 1: Answer: The Constitution of the Islamic Republic of Pakistan was passed on 10th April 1973 and authenticated by the President of the Assembly on 12th April 1973.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step\n",
            "ANN Predicted Answer: Answer: The Constitution of the Islamic Republic of Pakistan was passed on 10th April 1973 and authenticated by the President of the Assembly on 12th April 1973.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963ms/step\n",
            "LSTM Predicted Answer: Answer: According to the text, the President has the power to direct the Governor of any province to discharge as his Agent. This can be either generally or in any particular matter, relating to such areas in the Federation which are not included in any Province as may be specified in the direction.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933ms/step\n",
            "GRU Predicted Answer: Answer: The legal practitioner should be a Muslim and must have been enrolled as an advocate of a High Court for a period of not less than five years or as an advocate of the Supreme Court. The practitioner could also be a jurisconsult selected by the party from a panel of jurisconsults maintained by the Court. To be eligible to be on the panel of jurisconsults, a person should be an aalim who, in the opinion of the Court, is well-versed in Shariat. The legal practitioner or jurisconsult is not supposed to plead for the\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001C16084A2A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001C16084A2A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763ms/step\n",
            "Enhanced LSTM Predicted Answer: Answer: The Constitution of the Islamic Republic of Pakistan was passed on 10th April 1973 and authenticated by the President of the Assembly on 12th April 1973.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001C16084B2E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001C16084B2E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803ms/step\n",
            "Enhanced GRU Predicted Answer: Answer: The Constitution of the Islamic Republic of Pakistan was passed on 10th April 1973 and authenticated by the President of the Assembly on 12th April 1973.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606ms/step\n",
            "Enhanced CNN Predicted Answer: Answer: The Constitution of the Islamic Republic of Pakistan was passed on 10th April 1973 and authenticated by the President of the Assembly on 12th April 1973.\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Question 2: Question: When was the Constitution of the Islamic Republic of Pakistan initially passed and subsequently authenticated?\n",
            "Correct Answer 2: Answer: The Constitution of the Islamic Republic of Pakistan was initially passed by the National Assembly of Pakistan on 10th April 1973, and it was authenticated by the President of the Assembly on 12th April 1973.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
            "ANN Predicted Answer: Answer: The Constitution of the Islamic Republic of Pakistan was initially passed by the National Assembly of Pakistan on 10th April 1973, and it was authenticated by the President of the Assembly on 12th April 1973.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n",
            "LSTM Predicted Answer: Answer: The operating expenses of a hydro-electric station include any sums payable as taxes, duties, interest or return on investment, depreciations and element of obsolescence, overheads, and provision for reserves.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
            "GRU Predicted Answer: Answer: The nomination of members from the Treasury Benches is made by the Leader of the House and from the Opposition Benches by the Leader of the Opposition.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
            "Enhanced LSTM Predicted Answer: Answer: The Constitution of the Islamic Republic of Pakistan was initially passed by the National Assembly of Pakistan on 10th April 1973, and it was authenticated by the President of the Assembly on 12th April 1973.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
            "Enhanced GRU Predicted Answer: Answer: The Constitution of the Islamic Republic of Pakistan was initially passed by the National Assembly of Pakistan on 10th April 1973, and it was authenticated by the President of the Assembly on 12th April 1973.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
            "Enhanced CNN Predicted Answer: Answer: The Constitution of the Islamic Republic of Pakistan was initially passed by the National Assembly of Pakistan on 10th April 1973, and it was authenticated by the President of the Assembly on 12th April 1973.\n",
            "\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def predict_answer(question, model):\n",
        "    seq = tokenizer.texts_to_sequences([question])\n",
        "    padded_seq = pad_sequences(seq, maxlen=max_length, padding='post')\n",
        "    prediction = np.argmax(model.predict(padded_seq), axis=-1)\n",
        "    return label_encoder.inverse_transform(prediction)[0]\n",
        "\n",
        "# Get the first two questions and their correct answers from your dataset\n",
        "first_two_questions = questions[:2]\n",
        "first_two_answers = answers[:2]\n",
        "\n",
        "# Loop through the first two questions and get predictions from all models\n",
        "for i, question in enumerate(first_two_questions):\n",
        "    print(f\"Question {i+1}: {question}\")\n",
        "    print(f\"Correct Answer {i+1}: {first_two_answers[i]}\")\n",
        "\n",
        "    # Test with LSTM model\n",
        "    predicted_answer_ann = predict_answer(question, ann_model)\n",
        "    print(f\"ANN Predicted Answer: {predicted_answer_ann}\")\n",
        "\n",
        "    # Test with LSTM model\n",
        "    predicted_answer_lstm = predict_answer(question, lstm_model)\n",
        "    print(f\"LSTM Predicted Answer: {predicted_answer_lstm}\")\n",
        "\n",
        "    # Test with GRU model\n",
        "    predicted_answer_gru = predict_answer(question, gru_model)\n",
        "    print(f\"GRU Predicted Answer: {predicted_answer_gru}\")\n",
        "\n",
        "    # Test with Enhanced LSTM model\n",
        "    predicted_answer_enhanced_lstm = predict_answer(question, lstm_enhanced_model)\n",
        "    print(f\"Enhanced LSTM Predicted Answer: {predicted_answer_enhanced_lstm}\")\n",
        "\n",
        "    # Test with Enhanced GRU model\n",
        "    predicted_answer_enhanced_gru = predict_answer(question, gru_enhanced_model)\n",
        "    print(f\"Enhanced GRU Predicted Answer: {predicted_answer_enhanced_gru}\")\n",
        "\n",
        "    # Test with Enhanced CNN model\n",
        "    predicted_answer_enhanced_cnn = predict_answer(question, cnn_enhanced_model)\n",
        "    print(f\"Enhanced CNN Predicted Answer: {predicted_answer_enhanced_cnn}\")\n",
        "\n",
        "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
